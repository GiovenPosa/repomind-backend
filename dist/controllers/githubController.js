"use strict";
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.GitHubController = void 0;
const crypto_1 = __importDefault(require("crypto"));
const dotenv = __importStar(require("dotenv"));
dotenv.config(); // ‚Üê load env first
const client_s3_1 = require("@aws-sdk/client-s3");
const s3Util_1 = require("../utils/s3Util");
const ingestService_1 = require("../services/ingestService");
const parserService_1 = require("../services/parserService");
const openaiEmbedder_1 = require("../ai/adapters/openaiEmbedder");
const embedService_1 = require("../services/embedService");
const indexerService_1 = require("../services/indexerService");
const docs_1 = require("../types/docs");
const documentationService_1 = require("../services/documentationService");
const confluencePublisher_1 = require("../services/confluencePublisher");
// one S3 client for the process
const s3 = new client_s3_1.S3Client({
    region: process.env.AWS_REGION || "eu-west-2",
});
// defaults you can tweak or read from env
const DEFAULT_INCLUDE = [
    "src/**",
    "README.md",
    ".github/workflows/**",
    "package.json",
    "tsconfig*.json",
    "Dockerfile",
    "scripts/**"
];
const DEFAULT_EXCLUDE = [
    "node_modules/**",
    "dist/**",
    "coverage/**",
    "**/*.map",
    "**/*.png", "**/*.jpg", "**/*.jpeg", "**/*.gif", "**/*.pdf", "**/*.zip"
];
function buildCfg() {
    return {
        include: DEFAULT_INCLUDE,
        exclude: DEFAULT_EXCLUDE,
        maxFileKB: 800,
    };
}
function buildLayout(tenantId, owner, repo, commit) {
    return {
        bucket: process.env.S3_BUCKET_NAME,
        tenantId: tenantId ?? "default",
        owner,
        repo,
        commit
    };
}
function cleanBranch(ref) {
    if (!ref)
        return undefined;
    return ref.replace(/^refs\/heads\//, "");
}
async function queueIngest(opts) {
    const { owner, repo, commit, branch, tenantId, installationId } = opts;
    setImmediate(async () => {
        try {
            const cfg = buildCfg();
            // 1) INGEST
            const manifest = await (0, ingestService_1.ingestRepository)({
                owner, repo, commit, branch, cfg, s3,
                layout: buildLayout(tenantId, owner, repo, commit),
                dryRun: false, saveTarball: true,
                installationId,
            });
            const commitSha = manifest.commit;
            console.log(`‚úÖ Ingest complete for ${owner}/${repo} @ ${commitSha}`);
            // DB: commit row
            await (0, indexerService_1.saveCommitRow)(manifest);
            // 2) PARSE
            await (0, parserService_1.parseCommit)({
                s3,
                layout: { bucket: process.env.S3_BUCKET_NAME, tenantId: tenantId ?? "default", owner, repo, commit: commitSha },
                writePerFileJsonl: true, modelLabel: "chunker-v0.1", targetTokensPerChunk: 1600,
            });
            console.log(`üß© Parse complete ‚Üí s3://${process.env.S3_BUCKET_NAME}/.../parse/`);
            // DB: chunk metadata
            const idxKey = `${(0, s3Util_1.s3Prefix)({ tenantId: tenantId ?? "default", owner, repo })}commits/${commitSha}/parse/chunks.index.json`;
            const index = await (0, s3Util_1.getJson)(s3, process.env.S3_BUCKET_NAME, idxKey);
            await (0, indexerService_1.upsertChunks)(owner, repo, commitSha, index.chunks);
            // 3) EMBED ‚Üí S3 + DB
            if (!process.env.OPENAI_API_KEY) {
                console.warn("‚ö†Ô∏è Skipping embeddings: OPENAI_API_KEY is not set.");
                return;
            }
            const embedder = new openaiEmbedder_1.OpenAIEmbedder({
                apiKey: process.env.OPENAI_API_KEY,
                model: process.env.OPENAI_EMBED_MODEL || "text-embedding-3-small",
            });
            const embedResult = await (0, embedService_1.embedCommit)({
                s3,
                layout: { bucket: process.env.S3_BUCKET_NAME, tenantId: tenantId ?? "default", owner, repo, commit: commitSha },
                embedder,
                batchSize: 64,
                partSize: 2000,
                onBatchVectors: async (rows) => {
                    await (0, indexerService_1.insertEmbeddings)(embedder.name, embedder.dim, rows);
                },
            });
            console.log(`üß† Embeddings complete ‚Üí ${embedResult.total} vectors (provider=${embedResult.provider})`);
            // 4) DOCS ‚Üí generate in memory and publish to Confluence
            try {
                if (!process.env.OPENAI_API_KEY) {
                    console.warn("‚ö†Ô∏è Skipping docs generation: OPENAI_API_KEY is not set.");
                }
                else {
                    const pages = await (0, documentationService_1.generateDocsPages)({
                        owner,
                        repo,
                        commit: commitSha,
                        tenantId: tenantId ?? "default",
                        bucket: process.env.S3_BUCKET_NAME,
                        sections: docs_1.DEFAULT_SECTIONS,
                    });
                    // Build a stable per-repo space key (no .env override needed)
                    const rawSpaceKey = `${owner}_${repo}`;
                    const spaceKey = (0, confluencePublisher_1.normalizeSpaceKey)(rawSpaceKey);
                    console.log("üß≠ Confluence target");
                    console.log("   ‚Ä¢ base:", process.env.CONFLUENCE_BASE_URL);
                    console.log("   ‚Ä¢ spaceKey:", spaceKey);
                    console.log("   ‚Ä¢ spaceName:", `${(0, confluencePublisher_1.toTitleCase)(repo)} Docs`);
                    console.log("   ‚Ä¢ rootTitle:", "Code Base Documentation");
                    console.log("   ‚Ä¢ pageCount:", pages.length);
                    const publishResult = await (0, confluencePublisher_1.upsertPageTree)({
                        spaceKey,
                        spaceName: `${(0, confluencePublisher_1.toTitleCase)(repo)} Docs`,
                        spaceDesc: `RepoMind automated docs for ${owner}/${repo} @ ${commitSha}`,
                        rootTitle: "Code Base Documentation",
                        pages,
                    }, {
                        deleteMissing: true,
                        ignoreTitles: [],
                        dryRun: false, // set true to see logs first without changes
                    });
                    console.log("üöÄ Published docs to Confluence", {
                        spaceId: publishResult.spaceId,
                        rootId: publishResult.rootId,
                        repo: `${owner}/${repo}`,
                        commit: commitSha,
                    });
                }
            }
            catch (e) {
                // Detailed Axios error logging for fast diagnosis
                const status = e?.response?.status;
                const data = e?.response?.data;
                console.error("Docs generation/publish failed:", {
                    message: e?.message,
                    status,
                    data,
                });
            }
        }
        catch (err) {
            console.error(`‚ùå Ingest/Parse/Embed/Publish failed for ${owner}/${repo} @ ${commit}`, err);
        }
    });
}
class GitHubController {
    static async getUserRepose(req, res) {
        try {
            res.json({
                message: "Get user repos endpoint",
                status: "Not implemented yet"
            });
        }
        catch (error) {
            res.status(500).json({
                error: "Failed to fetch repositories",
                message: error instanceof Error ? error.message : 'Unknown error'
            });
        }
    }
    static async handleWebhook(req, res) {
        try {
            const eventType = req.headers['x-github-event'];
            const signature = req.headers['x-hub-signature-256'] || '';
            const deliveryId = req.headers['x-github-delivery'];
            // Use raw bytes for HMAC (fallback to JSON string if not present)
            const raw = req.rawBody ?? Buffer.from(JSON.stringify(req.body || {}));
            if (process.env.GITHUB_WEBHOOK_SECRET) {
                const isValid = GitHubController.verifyWebhookSignature(raw, signature, process.env.GITHUB_WEBHOOK_SECRET);
                if (!isValid) {
                    console.error('‚ùå Invalid webhook signature!', { deliveryId, eventType });
                    return res.status(401).json({ error: 'Invalid signature' });
                }
                console.log('‚úÖ Webhook signature verified successfully');
            }
            else {
                console.warn('‚ö†Ô∏è  No webhook secret configured - skipping verification');
            }
            console.log('\nüîî GitHub Webhook Received:');
            console.log('‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ');
            console.log('‚îÇ Event Type:', eventType);
            console.log('‚îÇ Delivery ID:', deliveryId);
            console.log('‚îÇ Timestamp:', new Date().toISOString());
            console.log('‚îÇ From App:', process.env.GITHUB_APP_ID);
            console.log('‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ');
            // If body is still a Buffer (e.g., when using express.raw), parse it now
            const payload = Buffer.isBuffer(req.body)
                ? JSON.parse(req.body.toString('utf8'))
                : req.body;
            // Store webhook event
            GitHubController.webhookEvents.push({
                eventType,
                deliveryId,
                timestamp: new Date().toISOString(),
                payload
            });
            // Process events
            switch (eventType) {
                case 'ping':
                    GitHubController.handlePingEvent(payload);
                    break;
                case 'repository':
                    await GitHubController.handleRepositoryEvent(payload);
                    break;
                case 'push':
                    GitHubController.handlePushEvent(payload);
                    break;
                case 'pull_request':
                    GitHubController.handlePullRequestEvent(payload);
                    break;
                case 'issues':
                    GitHubController.handleIssuesEvent(payload);
                    break;
                case 'star':
                    GitHubController.handleStarEvent(payload);
                    break;
                case 'fork':
                    GitHubController.handleForkEvent(payload);
                    break;
                case 'installation':
                    console.log('üîß Installation event:', payload.action);
                    break;
                case 'installation_repositories':
                    console.log('üì¶ Installation repositories changed:', payload.action);
                    break;
                default:
                    console.log(`üìå Unhandled event type: ${eventType}`);
            }
            return res.status(200).json({
                message: 'Webhook received successfully',
                eventType,
                deliveryId,
                timestamp: new Date().toISOString()
            });
        }
        catch (error) {
            console.error('‚ùå Webhook processing error:', error);
            return res.status(500).json({
                error: 'Failed to process webhook',
                message: error instanceof Error ? error.message : 'Unknown error'
            });
        }
    }
    /**
     * Get webhook status for debugging
     */
    static async getWebhookStatus(req, res) {
        try {
            const recentEvents = GitHubController.webhookEvents.slice(-5).map(e => ({
                type: e.eventType,
                deliveryId: e.deliveryId,
                timestamp: e.timestamp
            }));
            res.json({
                status: 'active',
                endpoint: `${req.protocol}://${req.get('host')}/api/github/webhook`,
                appId: process.env.GITHUB_APP_ID,
                eventsConfigured: [
                    'repository (NEW REPO DETECTION)',
                    'ping',
                    'push',
                    'pull_request',
                    'issues',
                    'star',
                    'fork',
                    'installation'
                ],
                secretConfigured: !!process.env.GITHUB_WEBHOOK_SECRET,
                totalEventsReceived: GitHubController.webhookEvents.length,
                recentEvents,
                newReposDetected: GitHubController.newRepositories.length,
                lastNewRepo: GitHubController.newRepositories[GitHubController.newRepositories.length - 1] || null
            });
        }
        catch (error) {
            res.status(500).json({
                error: 'Failed to get webhook status',
                message: error instanceof Error ? error.message : 'Unknown error'
            });
        }
    }
    /**
     * Get list of newly created repositories
     */
    static async getNewRepositories(req, res) {
        try {
            res.json({
                count: GitHubController.newRepositories.length,
                repositories: GitHubController.newRepositories,
                message: 'Repositories detected since server started'
            });
        }
        catch (error) {
            res.status(500).json({
                error: 'Failed to get new repositories',
                message: error instanceof Error ? error.message : 'Unknown error'
            });
        }
    }
    /**
     * Verify webhook signature from GitHub
     */
    static verifyWebhookSignature(payload, signatureHeader, secret) {
        if (!signatureHeader || !secret) {
            console.warn('‚ö†Ô∏è  Webhook signature or secret missing', { hasHeader: !!signatureHeader, hasSecret: !!secret });
            return false;
        }
        const expected = 'sha256=' + crypto_1.default.createHmac('sha256', secret).update(payload).digest('hex');
        try {
            const a = Buffer.from(signatureHeader, 'utf8');
            const b = Buffer.from(expected, 'utf8');
            if (a.length !== b.length)
                return false;
            return crypto_1.default.timingSafeEqual(a, b);
        }
        catch (err) {
            console.error('Signature verification error:', err);
            return false;
        }
    }
    // Event-specific handlers
    static handlePingEvent(payload) {
        console.log('\n‚úÖ WEBHOOK PING SUCCESSFUL!');
        console.log('‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ');
        console.log('‚îÇ Hook ID:', payload.hook?.id || payload.hook_id);
        console.log('‚îÇ App ID:', payload.hook?.app_id);
        console.log('‚îÇ Zen:', payload.zen);
        if (payload.repository) {
            console.log('‚îÇ Repository:', payload.repository.full_name);
            console.log('‚îÇ Sender:', payload.sender?.login);
        }
        console.log('‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ');
        console.log('\nüéâ Your GitHub App webhook is working!\n');
    }
    static async handleRepositoryEvent(payload) {
        console.log('\nüìö REPOSITORY Event:');
        console.log('   Action:', payload.action);
        console.log('   Repository:', payload.repository?.full_name);
        console.log('   Private:', payload.repository?.private ? 'Yes' : 'No');
        console.log('   Owner:', payload.repository?.owner?.login);
        // NEW REPOSITORY CREATED - ingest initial snapshot off default branch (if any)
        if (payload.action === 'created') {
            console.log('\n');
            console.log('‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó');
            console.log('‚ïë    üéâ NEW REPOSITORY DETECTED! üéâ      ‚ïë');
            console.log('‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù');
            console.log('');
            console.log('üìã Repository Details:');
            console.log('‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ');
            console.log('‚îÇ Name:', payload.repository.name);
            console.log('‚îÇ Full Name:', payload.repository.full_name);
            console.log('‚îÇ Private:', payload.repository.private ? 'üîí Yes' : 'üåç No');
            console.log('‚îÇ Description:', payload.repository.description || 'No description');
            console.log('‚îÇ Default Branch:', payload.repository.default_branch);
            console.log('‚îÇ Created At:', new Date(payload.repository.created_at).toLocaleString());
            console.log('‚îÇ Owner:', payload.repository.owner.login);
            console.log('‚îÇ Created By:', payload.sender.login);
            console.log('‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ');
            const newRepo = {
                id: payload.repository.id,
                name: payload.repository.name,
                fullName: payload.repository.full_name,
                private: payload.repository.private,
                description: payload.repository.description,
                createdAt: payload.repository.created_at,
                detectedAt: new Date().toISOString(),
                owner: payload.repository.owner.login,
                createdBy: payload.sender.login,
                defaultBranch: payload.repository.default_branch
            };
            GitHubController.newRepositories.push(newRepo);
            console.log('\n‚úÖ Repository added to tracking system');
            // Kick off an initial ingest (if repo has a default branch / content)
            try {
                const owner = payload.repository.owner.login;
                const repo = payload.repository.name;
                const defaultBranch = payload.repository.default_branch || "main";
                const installationId = payload.installation?.id;
                queueIngest({
                    owner,
                    repo,
                    commit: defaultBranch,
                    branch: defaultBranch,
                    installationId,
                });
            }
            catch (e) {
                console.warn("‚ö†Ô∏è Initial ingest attempt failed (likely empty repo):", e instanceof Error ? e.message : e);
            }
        }
        // Handle other repository actions
        switch (payload.action) {
            case 'deleted':
                console.log('   ‚ùå Repository was DELETED');
                break;
            case 'archived':
                console.log('   üì¶ Repository was ARCHIVED');
                break;
            case 'unarchived':
                console.log('   üìÇ Repository was UNARCHIVED');
                break;
            case 'renamed':
                console.log('   ‚úèÔ∏è  Repository was RENAMED');
                break;
            case 'transferred':
                console.log('   ‚û°Ô∏è  Repository was TRANSFERRED');
                break;
            case 'publicized':
                console.log('   üåç Repository was made PUBLIC');
                break;
            case 'privatized':
                console.log('   üîí Repository was made PRIVATE');
                break;
        }
    }
    static handlePushEvent(payload) {
        console.log('üì¶ PUSH Event:');
        console.log('   Repository:', payload.repository?.full_name);
        console.log('   Branch:', payload.ref?.replace('refs/heads/', ''));
        console.log('   Pusher:', payload.pusher?.name);
        console.log('   Commits:', payload.commits?.length || 0);
        // Log each commit (first 3)
        payload.commits?.slice(0, 3).forEach((commit, index) => {
            console.log(`   Commit ${index + 1}:`, commit.message.split('\n')[0]);
            console.log(`     Author: ${commit.author?.name}`);
            console.log(`     SHA: ${commit.id?.substring(0, 7)}`);
        });
        // Kick ingest for head commit
        try {
            const owner = payload.repository?.owner?.name || payload.repository?.owner?.login;
            const repo = payload.repository?.name;
            const commitSha = payload.after || payload.head_commit?.id; // head SHA
            const branch = cleanBranch(payload.ref); // "main"
            const installationId = payload.installation?.id;
            if (!owner || !repo || !commitSha) {
                console.warn('‚ö†Ô∏è Missing owner/repo/commitSha in push payload; skipping ingest.');
                return;
            }
            queueIngest({
                owner,
                repo,
                commit: commitSha,
                branch,
                tenantId: undefined,
                installationId,
            });
        }
        catch (e) {
            console.error('‚ùå Failed to queue ingest for push:', e);
        }
    }
    static handlePullRequestEvent(payload) {
        console.log('üîÄ PULL REQUEST Event:');
        console.log('   Action:', payload.action);
        console.log('   PR #:', payload.pull_request?.number);
        console.log('   Title:', payload.pull_request?.title);
        console.log('   Author:', payload.pull_request?.user?.login);
        console.log('   Base:', payload.pull_request?.base?.ref);
        console.log('   Head:', payload.pull_request?.head?.ref);
        console.log('   State:', payload.pull_request?.state);
    }
    static handleIssuesEvent(payload) {
        console.log('üìù ISSUES Event:');
        console.log('   Action:', payload.action);
        console.log('   Issue #:', payload.issue?.number);
        console.log('   Title:', payload.issue?.title);
        console.log('   Author:', payload.issue?.user?.login);
        console.log('   State:', payload.issue?.state);
        console.log('   Labels:', payload.issue?.labels?.map((l) => l.name).join(', '));
    }
    static handleStarEvent(payload) {
        console.log('‚≠ê STAR Event:');
        console.log('   Action:', payload.action);
        console.log('   Repository:', payload.repository?.full_name);
        console.log('   Stars Count:', payload.repository?.stargazers_count);
        console.log('   Starred by:', payload.sender?.login);
    }
    static handleForkEvent(payload) {
        console.log('üç¥ FORK Event:');
        console.log('   Repository:', payload.repository?.full_name);
        console.log('   Forks Count:', payload.repository?.forks_count);
        console.log('   Forked by:', payload.sender?.login);
        console.log('   Fork Name:', payload.forkee?.full_name);
    }
}
exports.GitHubController = GitHubController;
// Store new repositories in memory (use database in production)
GitHubController.newRepositories = [];
GitHubController.webhookEvents = [];
exports.default = GitHubController;
